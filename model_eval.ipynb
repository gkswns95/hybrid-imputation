{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import animation\n",
    "from datatools.trace_animator import TraceAnimator\n",
    "from datatools.trace_helper import TraceHelper\n",
    "from datatools.visualize_helper import VisualizeHelper\n",
    "from datatools.nba_helper import NBADataHelper, NBADataAnimator\n",
    "from datatools.nfl_helper import NFLDataHelper\n",
    "\n",
    "from models import load_model\n",
    "from models.utils import print_helper, reshape_tensor, get_dataset_config, normalize_tensor\n",
    "\n",
    "from models.graph_imputer.graph_imputer import BidirectionalGraphImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluating on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial = 222\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"model\"] == \"nrtsi\":\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "\n",
    "    gap_models = dict()\n",
    "    gap_models[1] = f\"{save_path}/model/nrtsi_state_dict_best_gap_1.pt\"\n",
    "    gap_models[2] = f\"{save_path}/model/nrtsi_state_dict_best_gap_2.pt\"\n",
    "    gap_models[4] = f\"{save_path}/model/nrtsi_state_dict_best_gap_4.pt\"\n",
    "    gap_models[8] = f\"{save_path}/model/nrtsi_state_dict_best_gap_8.pt\"\n",
    "    gap_models[16] = f\"{save_path}/model/nrtsi_state_dict_best_gap_16.pt\"\n",
    "\n",
    "    for k in gap_models:\n",
    "        gap_models[k] = torch.load(gap_models[k], map_location=lambda storage, _: storage)\n",
    "else:\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: dbhp\n",
      "- Compute stats for naive baselines: True\n"
     ]
    }
   ],
   "source": [
    "sports = params[\"dataset\"]\n",
    "model_type = params[\"model\"]\n",
    "naive_baselines = True\n",
    "\n",
    "if model_type == \"dbhp\":\n",
    "    deriv_accum = params[\"deriv_accum\"]\n",
    "    dynamic_hybrid = params[\"dynamic_hybrid\"]\n",
    "\n",
    "print(f\"- Sports: {sports}\")\n",
    "print(f\"- Model type: {model_type}\")\n",
    "print(f\"- Compute stats for naive baselines: {naive_baselines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n"
     ]
    }
   ],
   "source": [
    "metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "nba_files = os.listdir(\"data/nba_traces\")\n",
    "nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "nba_paths.sort()\n",
    "\n",
    "nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "nfl_paths.sort()\n",
    "\n",
    "if sports == \"soccer\":\n",
    "    trace_helper = TraceHelper\n",
    "    test_data_paths = metrica_paths[3:4]\n",
    "elif sports == \"basketball\":\n",
    "    trace_helper = NBADataHelper\n",
    "    test_data_paths = nba_paths[90:]\n",
    "else: # e.g. \"American football\"\n",
    "    trace_helper = NFLDataHelper\n",
    "    test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "print(f\"Test data paths: {test_data_paths}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n",
      "Phase 3: 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Phase 7: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]\n",
      "Phase 9: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n",
      "Phase 10: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n",
      "Phase 11: 100%|██████████| 7/7 [00:08<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pe</th>\n",
       "      <th>se</th>\n",
       "      <th>sce</th>\n",
       "      <th>ple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>2.135689</td>\n",
       "      <td>0.782768</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.011214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dap_f</th>\n",
       "      <td>2.107197</td>\n",
       "      <td>0.576114</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.012526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dap_b</th>\n",
       "      <td>2.118469</td>\n",
       "      <td>0.577828</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.012497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_s</th>\n",
       "      <td>2.037109</td>\n",
       "      <td>0.579688</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_s2</th>\n",
       "      <td>2.009928</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.013421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_d</th>\n",
       "      <td>2.005881</td>\n",
       "      <td>0.536693</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.013356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>5.372363</td>\n",
       "      <td>1.186698</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.046397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>7.809323</td>\n",
       "      <td>6.283521</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.142324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffill</th>\n",
       "      <td>10.354956</td>\n",
       "      <td>3.620982</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.046397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pe        se       sce       ple\n",
       "pred        2.135689  0.782768  0.000028  0.011214\n",
       "dap_f       2.107197  0.576114  0.000016  0.012526\n",
       "dap_b       2.118469  0.577828  0.000017  0.012497\n",
       "hybrid_s    2.037109  0.579688  0.000016  0.012852\n",
       "hybrid_s2   2.009928  0.538293  0.000015  0.013421\n",
       "hybrid_d    2.005881  0.536693  0.000015  0.013356\n",
       "linear      5.372363  1.186698  0.000042  0.046397\n",
       "knn         7.809323  6.283521  0.001897  0.142324\n",
       "ffill      10.354956  3.620982  0.001565  0.046397"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_keys = [\"pred\"]\n",
    "if model_type == \"dbhp\":\n",
    "    if model.params[\"deriv_accum\"]:\n",
    "        pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "    if model.params[\"dynamic_hybrid\"]:\n",
    "        pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "if naive_baselines:\n",
    "    pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "for path in test_data_paths:\n",
    "    print()\n",
    "    print(f\"{path}:\")\n",
    "    match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "    helper = trace_helper(traces=match_traces)\n",
    "\n",
    "    if model_type == \"nrtsi\":\n",
    "        match_ret, match_stats = helper.predict(\n",
    "            model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "        )\n",
    "    else:\n",
    "        match_ret, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "\n",
    "    for k, v in match_stats.items():\n",
    "        stats[k] += v\n",
    "\n",
    "# print(\"Total Performance:\")\n",
    "# print_helper(ret, pred_keys, trial=trial, save_txt=True)\n",
    "\n",
    "# torch.save(helper, f\"{save_path}/helper\")\n",
    "# torch.save(ret, f\"{save_path}/df_dict\")\n",
    "\n",
    "n_players, _ = get_dataset_config(sports)\n",
    "stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "for k, v in stats.items():\n",
    "    if k in [\"total_frames\", \"missing_frames\"]:\n",
    "        continue\n",
    "    \n",
    "    pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "    metric = k.split(\"_\")[-1]\n",
    "\n",
    "    if metric in [\"pe\", \"se\"]:\n",
    "        stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "        \n",
    "    elif metric in [\"sce\", \"ple\"]:\n",
    "        stats[k] = round(v / (stats[\"total_frames\"] * n_players), 6)\n",
    "\n",
    "    stats_df.at[pred_key, metric] = stats[k]\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Get Main model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 3003\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "if os.path.isfile(save_path + \"/df_dict\"):\n",
    "    helper =  torch.load(save_path + \"/helper\")\n",
    "    df_dict = torch.load(save_path + \"/df_dict\")\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Add baseline model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_dict = {4000 : \"brits\", 5000 : \"naomi\", 214 : \"nrtsi\"} # Metrica\n",
    "trial_dict = {4003 : \"brits\", 5001 : \"naomi\", 6001 : \"nrtsi\", 9996 : \"graphimputer\"} # NBA\n",
    "for (t, model_type) in trial_dict.items():\n",
    "    save_path = f\"saved/{t:03d}\"\n",
    "    if os.path.isfile(save_path + \"/df_dict\"):\n",
    "        df_dict_ = torch.load(save_path + \"/df_dict\")\n",
    "        df_dict[f\"{model_type}_df\"] = df_dict_[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Soccer Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.traces[\"episode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 479\n",
    "i1 = 873\n",
    "\n",
    "animator = TraceAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    mask = df_dict[\"mask\"][i0:i1],\n",
    "    show_episodes=True,\n",
    "    show_events=False,\n",
    "    show_frames=False,\n",
    "    show_polygon=True,\n",
    "    annot_cols=None,\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Basketball Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 326\n",
    "i1 = 737\n",
    "animator = NBADataAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    show_episodes=True,\n",
    "    show_frames=True,\n",
    "    masks = df_dict[\"mask\"][i0:i1],\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = \"imputed_traj\" # \"imputed_traj\", \"dist_heatmap\", \"weights_heatmap\"\n",
    "sports = params[\"dataset\"]\n",
    "visualizer = VisualizeHelper(trial, df_dict, plot_mode, dataset=sports, helper=helper)\n",
    "visualizer.valid_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_run(epi_idx=0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c44ecce01b6920a996c2e45a7791c773f725b79a727cce05b077a0ad48ece758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
