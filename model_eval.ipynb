{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "\n",
    "from dataset import SportsDataset\n",
    "from datatools.trace_animator import TraceAnimator\n",
    "from datatools.trace_helper import TraceHelper\n",
    "from datatools.visualize_helper import VisualizeHelper\n",
    "from datatools.nba_helper import NBADataHelper, NBADataAnimator\n",
    "from datatools.nfl_helper import NFLDataHelper\n",
    "from models import load_model\n",
    "from models.utils import get_dataset_config, print_helper, reshape_tensor, sort_players\n",
    "\n",
    "from models.graph_imputer.graph_imputer import BidirectionalGraphImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluating on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial = 1357\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"model\"] == \"nrtsi\":\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "\n",
    "    gap_models = dict()\n",
    "    gap_models[1] = f\"{save_path}/model/nrtsi_state_dict_best_gap_1.pt\"\n",
    "    gap_models[2] = f\"{save_path}/model/nrtsi_state_dict_best_gap_2.pt\"\n",
    "    gap_models[4] = f\"{save_path}/model/nrtsi_state_dict_best_gap_4.pt\"\n",
    "    gap_models[8] = f\"{save_path}/model/nrtsi_state_dict_best_gap_8.pt\"\n",
    "    gap_models[16] = f\"{save_path}/model/nrtsi_state_dict_best_gap_16.pt\"\n",
    "\n",
    "    for k in gap_models:\n",
    "        gap_models[k] = torch.load(gap_models[k], map_location=lambda storage, _: storage)\n",
    "else:\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n"
     ]
    }
   ],
   "source": [
    "sports = params[\"dataset\"]\n",
    "model_type = params[\"model\"]\n",
    "naive_baselines = True\n",
    "\n",
    "if model_type == \"dbhp\":\n",
    "    deriv_accum = params[\"deriv_accum\"]\n",
    "    dynamic_hybrid = params[\"dynamic_hybrid\"]\n",
    "\n",
    "print(f\"- Sports: {sports}\")\n",
    "print(f\"- Model type: {model_type}\")\n",
    "print(f\"- Compute stats for naive baselines: {naive_baselines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n"
     ]
    }
   ],
   "source": [
    "metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "nba_files = os.listdir(\"data/nba_traces\")\n",
    "nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "nba_paths.sort()\n",
    "\n",
    "nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "nfl_paths.sort()\n",
    "\n",
    "if sports == \"soccer\":\n",
    "    trace_helper = TraceHelper\n",
    "    test_data_paths = metrica_paths[3:4]\n",
    "elif sports == \"basketball\":\n",
    "    trace_helper = NBADataHelper\n",
    "    test_data_paths = nba_paths[90:]\n",
    "else: # e.g. \"American football\"\n",
    "    trace_helper = NFLDataHelper\n",
    "    test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "print(f\"Test data paths: {test_data_paths}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for testing a trial and printing performance statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(trial, model, params, sports=\"soccer\", naive_baselines=True):\n",
    "    sports = params[\"dataset\"]\n",
    "    model_type = params[\"model\"]\n",
    "    # naive_baselines = True\n",
    "\n",
    "    if model_type == \"dbhp\":\n",
    "        deriv_accum = params[\"deriv_accum\"]\n",
    "        dynamic_hybrid = params[\"dynamic_hybrid\"]\n",
    "\n",
    "    print(f\"- Sports: {sports}\")\n",
    "    print(f\"- Model type: {model_type}\")\n",
    "    print(f\"- Compute stats for naive baselines: {naive_baselines}\")\n",
    "\n",
    "    metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "    metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "    nba_files = os.listdir(\"data/nba_traces\")\n",
    "    nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "    nba_paths.sort()\n",
    "\n",
    "    nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "    nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "    nfl_paths.sort()\n",
    "\n",
    "    if sports == \"soccer\":\n",
    "        trace_helper = TraceHelper\n",
    "        test_data_paths = metrica_paths[3:4]\n",
    "    elif sports == \"basketball\":\n",
    "        trace_helper = NBADataHelper\n",
    "        test_data_paths = nba_paths[90:]\n",
    "    else: # e.g. \"American football\"\n",
    "        trace_helper = NFLDataHelper\n",
    "        test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "    print(f\"Test data paths: {test_data_paths}\")\n",
    "    print(f\"\\n---------- Trial {trial} ----------\")\n",
    "\n",
    "    pred_keys = [\"pred\"]\n",
    "    if model_type == \"dbhp\":\n",
    "        if model.params[\"deriv_accum\"]:\n",
    "            pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "        if model.params[\"dynamic_hybrid\"]:\n",
    "            pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "    if naive_baselines:\n",
    "        pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "    stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "    stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "    stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "    for path in test_data_paths:\n",
    "        print()\n",
    "        print(f\"{path}:\")\n",
    "        match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "        helper = trace_helper(traces=match_traces)\n",
    "\n",
    "        if params[\"model\"] == \"nrtsi\":\n",
    "            match_ret, match_stats = helper.predict(\n",
    "                model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "            )\n",
    "        else:\n",
    "            if sports != \"soccer\":\n",
    "                match_ret, match_stats = helper.predict(model, dataset=sports)\n",
    "            else:\n",
    "                match_ret, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "                \n",
    "\n",
    "        for k, v in match_stats.items():\n",
    "            stats[k] += v\n",
    "\n",
    "    # print(\"Total Performance:\")\n",
    "    # print_helper(ret, pred_keys, trial=trial, save_txt=True)\n",
    "\n",
    "    # torch.save(helper, f\"{save_path}/helper\")\n",
    "    # torch.save(ret, f\"{save_path}/df_dict\")\n",
    "\n",
    "    n_players, _ = get_dataset_config(sports)\n",
    "    stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "    for k, v in stats.items():\n",
    "        if k in [\"total_frames\", \"missing_frames\"]:\n",
    "            continue\n",
    "        \n",
    "        pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "        metric = k.split(\"_\")[-1]\n",
    "\n",
    "        if metric in [\"pe\", \"se\"]:\n",
    "            stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "            \n",
    "        elif metric in [\"sce\", \"ple\"]:\n",
    "            stats[k] = round(v / (stats[\"total_frames\"] * n_players), 6)\n",
    "\n",
    "        stats_df.at[pred_key, metric] = stats[k]\n",
    "\n",
    "    # print(f\"Total frames: {stats['total_frames'] * n_players}\")\n",
    "    # print(f\"Missing frames: {stats['missing_frames']}\")\n",
    "    print()\n",
    "    print(f\"Window size: {params['window_size']}\")\n",
    "    print(f\"Missing pattern: {params['missing_pattern']}\")\n",
    "    print(f\"Missing rate: {stats['missing_frames'] / (stats['total_frames'] * n_players):.4f}\")\n",
    "    # print(stats_df.loc[[\"pred\", \"dap_f\", \"dap_b\", \"hybrid_s2\", \"hybrid_d\", \"linear\"], \"pe\"])\n",
    "    print(stats_df.loc[[\"pred\", \"linear\"], \"pe\"])\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_stats(trial, model, params, sports=\"soccer\", naive_baselines=True):\n",
    "#     print(f\"\\n---------- Trial {trial} ----------\")\n",
    "\n",
    "#     pred_keys = [\"pred\"]\n",
    "#     if model_type == \"dbhp\":\n",
    "#         if model.params[\"deriv_accum\"]:\n",
    "#             pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "#         if model.params[\"dynamic_hybrid\"]:\n",
    "#             pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "#     if naive_baselines:\n",
    "#         pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "#     stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "#     stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "#     stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "#     for path in test_data_paths:\n",
    "#         print()\n",
    "#         print(f\"{path}:\")\n",
    "#         match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "#         helper = trace_helper(traces=match_traces)\n",
    "\n",
    "#         if params[\"model\"] == \"nrtsi\":\n",
    "#             match_ret, match_stats = helper.predict(\n",
    "#                 model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "#             )\n",
    "#         else:\n",
    "#             match_ret, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "\n",
    "#         for k, v in match_stats.items():\n",
    "#             stats[k] += v\n",
    "\n",
    "#     # print(\"Total Performance:\")\n",
    "#     # print_helper(ret, pred_keys, trial=trial, save_txt=True)\n",
    "\n",
    "#     # torch.save(helper, f\"{save_path}/helper\")\n",
    "#     # torch.save(ret, f\"{save_path}/df_dict\")\n",
    "\n",
    "#     n_players, _ = get_dataset_config(sports)\n",
    "#     stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "#     for k, v in stats.items():\n",
    "#         if k in [\"total_frames\", \"missing_frames\"]:\n",
    "#             continue\n",
    "        \n",
    "#         pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "#         metric = k.split(\"_\")[-1]\n",
    "\n",
    "#         if metric in [\"pe\", \"se\"]:\n",
    "#             stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "            \n",
    "#         elif metric in [\"sce\", \"ple\"]:\n",
    "#             stats[k] = round(v / (stats[\"total_frames\"] * n_players), 6)\n",
    "\n",
    "#         stats_df.at[pred_key, metric] = stats[k]\n",
    "\n",
    "#     # print(f\"Total frames: {stats['total_frames'] * n_players}\")\n",
    "#     # print(f\"Missing frames: {stats['missing_frames']}\")\n",
    "#     print()\n",
    "#     print(f\"Window size: {params['window_size']}\")\n",
    "#     print(f\"Missing pattern: {params['missing_pattern']}\")\n",
    "#     print(f\"Missing rate: {stats['missing_frames'] / (stats['total_frames'] * n_players):.4f}\")\n",
    "#     # print(stats_df.loc[[\"pred\", \"dap_f\", \"dap_b\", \"hybrid_s2\", \"hybrid_d\", \"linear\"], \"pe\"])\n",
    "#     print(stats_df.loc[[\"pred\", \"linear\"], \"pe\"])\n",
    "\n",
    "#     return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on Set Transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['window_size'] = 200\n",
    "params['missing_pattern'] = \"camera\"\n",
    "params['missing_rate'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_keys = [\"pred\"]\n",
    "if model_type == \"dbhp\":\n",
    "    if model.params[\"deriv_accum\"]:\n",
    "        pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "    if model.params[\"dynamic_hybrid\"]:\n",
    "        pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "if naive_baselines:\n",
    "    pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "stats = {k: 0 for k in stat_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in test_data_paths:\n",
    "    print()\n",
    "    print(f\"{path}:\")\n",
    "    match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "    helper = trace_helper(traces=match_traces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n",
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n",
      "\n",
      "---------- Trial 1357 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  10%|██▌                      | 1/10 [00:00<00:06,  1.38it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  20%|█████                    | 2/10 [00:01<00:06,  1.19it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  30%|███████▌                 | 3/10 [00:02<00:06,  1.02it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  40%|██████████               | 4/10 [00:03<00:05,  1.13it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  50%|████████████▌            | 5/10 [00:05<00:06,  1.32s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  70%|█████████████████▌       | 7/10 [00:06<00:02,  1.04it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  80%|████████████████████     | 8/10 [00:07<00:01,  1.02it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  90%|██████████████████████▌  | 9/10 [00:10<00:01,  1.56s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2: 100%|████████████████████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "Phase 3:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 3:  50%|█████████████             | 1/2 [00:00<00:00,  2.01it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 3: 100%|██████████████████████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6:   0%|                                  | 0/1 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 6: 100%|██████████████████████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "Phase 7:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 7:  50%|█████████████             | 1/2 [00:01<00:01,  1.12s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 7: 100%|██████████████████████████| 2/2 [00:02<00:00,  1.10s/it]\n",
      "Phase 8:   0%|                                  | 0/3 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8:  33%|████████▋                 | 1/3 [00:01<00:03,  1.55s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.82s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8: 100%|██████████████████████████| 3/3 [00:04<00:00,  1.35s/it]\n",
      "Phase 9:   0%|                                  | 0/4 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  25%|██████▌                   | 1/4 [00:00<00:02,  1.15it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  50%|█████████████             | 2/4 [00:02<00:02,  1.23s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  75%|███████████████████▌      | 3/4 [00:04<00:01,  1.75s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9: 100%|██████████████████████████| 4/4 [00:06<00:00,  1.71s/it]\n",
      "Phase 10:   0%|                                 | 0/6 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  17%|████▏                    | 1/6 [00:01<00:08,  1.67s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  33%|████████▎                | 2/6 [00:02<00:03,  1.09it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  50%|████████████▌            | 3/6 [00:02<00:02,  1.11it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  67%|████████████████▋        | 4/6 [00:03<00:01,  1.20it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  83%|████████████████████▊    | 5/6 [00:04<00:00,  1.28it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10: 100%|█████████████████████████| 6/6 [00:05<00:00,  1.10it/s]\n",
      "Phase 11:   0%|                                 | 0/7 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  14%|███▌                     | 1/7 [00:01<00:06,  1.10s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  29%|███████▏                 | 2/7 [00:01<00:03,  1.42it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  43%|██████████▋              | 3/7 [00:02<00:03,  1.13it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  57%|██████████████▎          | 4/7 [00:04<00:03,  1.17s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  71%|█████████████████▊       | 5/7 [00:04<00:01,  1.11it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  86%|█████████████████████▍   | 6/7 [00:06<00:01,  1.16s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:190: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11: 100%|█████████████████████████| 7/7 [00:07<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size: 200\n",
      "Missing pattern: camera\n",
      "Missing rate: 0.5375\n",
      "pred      20.772954\n",
      "linear     3.166009\n",
      "Name: pe, dtype: object\n",
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n",
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n",
      "\n",
      "---------- Trial 1360 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:197: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32).unsqueeze(0)\n",
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[1, 1, 253, 132]}, size=[1, -1, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mmissing_mode \u001b[38;5;241m=\u001b[39m mode[idx]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mprint_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 65\u001b[0m, in \u001b[0;36mprint_stats\u001b[0;34m(trial, model, params, sports, naive_baselines)\u001b[0m\n\u001b[1;32m     63\u001b[0m         match_ret, match_stats \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mpredict(model, dataset\u001b[38;5;241m=\u001b[39msports)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m         match_ret, match_stats \u001b[38;5;241m=\u001b[39m \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msports\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnaive_baselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaive_baselines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m match_stats\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     69\u001b[0m     stats[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[0;32m~/hybrid-imputation/datatools/trace_helper.py:359\u001b[0m, in \u001b[0;36mTraceHelper.predict\u001b[0;34m(self, model, dataset_type, min_episode_size, naive_baselines, gap_models)\u001b[0m\n\u001b[1;32m    356\u001b[0m ep_ball_traces \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(ep_traces[ball_cols]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 359\u001b[0m     ep_ret, ep_stats \u001b[38;5;241m=\u001b[39m \u001b[43mTraceHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mep_player_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mep_ball_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_episode_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnaive_baselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaive_baselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgap_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Update resulting DataFrames\u001b[39;00m\n\u001b[1;32m    372\u001b[0m pos_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m phase_player_cols \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_x\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_y\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/hybrid-imputation/datatools/trace_helper.py:244\u001b[0m, in \u001b[0;36mTraceHelper.predict_episode\u001b[0;34m(model, dataset_type, player_traces, ball_traces, pred_keys, window_size, min_window_size, naive_baselines, gap_models)\u001b[0m\n\u001b[1;32m    242\u001b[0m     window_ret \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(window_inputs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     window_ret \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Save results for the window\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m][i_from:i_to] \u001b[38;5;241m=\u001b[39m window_ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [ws, x]\u001b[39;00m\n",
      "File \u001b[0;32m~/hybrid-imputation/models/latentode/latent_ode.py:198\u001b[0m, in \u001b[0;36mLatentODE.forward\u001b[0;34m(self, data, mode, device)\u001b[0m\n\u001b[1;32m    196\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mask, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# [1, time, n_players]\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \ttime_gap \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(time_gap, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 198\u001b[0m \tmask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [bs, time, x_dim]\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \ttime_gap \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(time_gap, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, time, x_dim]\u001b[39;00m\n\u001b[1;32m    201\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[1, 1, 253, 132]}, size=[1, -1, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = [310, 320, 330, 331, 332, 220, 341, 342]\n",
    "# trial_ids = [i for i in range(1358, 1364)]\n",
    "trial_ids = [1357, 1360, 1361]\n",
    "# mode = ['camera', 'playerwise', 'playerwise', 'playerwise', 'uniform', 'uniform', 'uniform']\n",
    "mode = ['camera', 'playerwise', 'uniform']\n",
    "\n",
    "for idx, trial in enumerate(trial_ids):\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    team_size_dict = {\"soccer\": 11, \"basketball\": 5, \"football\": 3}\n",
    "    model.params['team_size'] = team_size_dict[model.dataset]\n",
    "    model.params['window_size'] = 200\n",
    "    model.params['missing_pattern'] = mode[idx]\n",
    "    model.params['missing_rate'] = 0.5\n",
    "    model.missing_mode = mode[idx]\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n",
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n",
      "\n",
      "---------- Trial 1360 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  10%|██▌                      | 1/10 [00:00<00:06,  1.30it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  20%|█████                    | 2/10 [00:02<00:09,  1.21s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  30%|███████▌                 | 3/10 [00:04<00:10,  1.49s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  40%|██████████               | 4/10 [00:04<00:07,  1.20s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  50%|████████████▌            | 5/10 [00:06<00:07,  1.50s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  70%|█████████████████▌       | 7/10 [00:08<00:03,  1.05s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  80%|████████████████████     | 8/10 [00:09<00:02,  1.04s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2:  90%|██████████████████████▌  | 9/10 [00:12<00:01,  1.57s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 2: 100%|████████████████████████| 10/10 [00:13<00:00,  1.32s/it]\n",
      "Phase 3:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 3:  50%|█████████████             | 1/2 [00:00<00:00,  2.09it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 3: 100%|██████████████████████████| 2/2 [00:01<00:00,  1.47it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6:   0%|                                  | 0/1 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 6: 100%|██████████████████████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Phase 7:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 7:  50%|█████████████             | 1/2 [00:01<00:01,  1.08s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 7: 100%|██████████████████████████| 2/2 [00:02<00:00,  1.06s/it]\n",
      "Phase 8:   0%|                                  | 0/3 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 8:  33%|████████▋                 | 1/3 [00:01<00:03,  1.52s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 8:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.77s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 8: 100%|██████████████████████████| 3/3 [00:03<00:00,  1.32s/it]\n",
      "Phase 9:   0%|                                  | 0/4 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 9:  25%|██████▌                   | 1/4 [00:00<00:02,  1.18it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 9:  50%|█████████████             | 2/4 [00:02<00:02,  1.18s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 9:  75%|███████████████████▌      | 3/4 [00:04<00:01,  1.69s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 9: 100%|██████████████████████████| 4/4 [00:06<00:00,  1.65s/it]\n",
      "Phase 10:   0%|                                 | 0/6 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10:  17%|████▏                    | 1/6 [00:01<00:07,  1.60s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10:  33%|████████▎                | 2/6 [00:01<00:03,  1.14it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10:  50%|████████████▌            | 3/6 [00:02<00:02,  1.15it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10:  67%|████████████████▋        | 4/6 [00:03<00:01,  1.24it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10:  83%|████████████████████▊    | 5/6 [00:04<00:00,  1.33it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 10: 100%|█████████████████████████| 6/6 [00:05<00:00,  1.14it/s]\n",
      "Phase 11:   0%|                                 | 0/7 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  14%|███▌                     | 1/7 [00:01<00:06,  1.07s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  29%|███████▏                 | 2/7 [00:01<00:03,  1.46it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  43%|██████████▋              | 3/7 [00:02<00:03,  1.17it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  57%|██████████████▎          | 4/7 [00:04<00:03,  1.13s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  71%|█████████████████▊       | 5/7 [00:04<00:01,  1.14it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11:  86%|█████████████████████▍   | 6/7 [00:06<00:01,  1.13s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "Phase 11: 100%|█████████████████████████| 7/7 [00:07<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size: 200\n",
      "Missing pattern: playerwise\n",
      "Missing rate: 0.5000\n",
      "pred      20.527509\n",
      "linear     5.411107\n",
      "Name: pe, dtype: object\n",
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n",
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n",
      "\n",
      "---------- Trial 1361 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'missing_len' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mmissing_mode \u001b[38;5;241m=\u001b[39m mode[idx]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mprint_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 65\u001b[0m, in \u001b[0;36mprint_stats\u001b[0;34m(trial, model, params, sports, naive_baselines)\u001b[0m\n\u001b[1;32m     63\u001b[0m         match_ret, match_stats \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mpredict(model, dataset\u001b[38;5;241m=\u001b[39msports)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m         match_ret, match_stats \u001b[38;5;241m=\u001b[39m \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msports\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnaive_baselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaive_baselines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m match_stats\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     69\u001b[0m     stats[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[0;32m~/hybrid-imputation/datatools/trace_helper.py:359\u001b[0m, in \u001b[0;36mTraceHelper.predict\u001b[0;34m(self, model, dataset_type, min_episode_size, naive_baselines, gap_models)\u001b[0m\n\u001b[1;32m    356\u001b[0m ep_ball_traces \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(ep_traces[ball_cols]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 359\u001b[0m     ep_ret, ep_stats \u001b[38;5;241m=\u001b[39m \u001b[43mTraceHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mep_player_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mep_ball_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_episode_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnaive_baselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnaive_baselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgap_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Update resulting DataFrames\u001b[39;00m\n\u001b[1;32m    372\u001b[0m pos_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m phase_player_cols \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_x\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_y\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/hybrid-imputation/datatools/trace_helper.py:244\u001b[0m, in \u001b[0;36mTraceHelper.predict_episode\u001b[0;34m(model, dataset_type, player_traces, ball_traces, pred_keys, window_size, min_window_size, naive_baselines, gap_models)\u001b[0m\n\u001b[1;32m    242\u001b[0m     window_ret \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(window_inputs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     window_ret \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Save results for the window\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m][i_from:i_to] \u001b[38;5;241m=\u001b[39m window_ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [ws, x]\u001b[39;00m\n",
      "File \u001b[0;32m~/hybrid-imputation/models/latentode/latent_ode.py:179\u001b[0m, in \u001b[0;36mLatentODE.forward\u001b[0;34m(self, data, mode, device)\u001b[0m\n\u001b[1;32m    172\u001b[0m missing_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m       \n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# mask = generate_mask(\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# \tinputs = input_dict,\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# \tmode = self.missing_mode, \u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# \tws = seq_len, \u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# \tmissing_rate = missing_probs[random.randint(1, 9)],\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# \tdataset= self.dataset)\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m mask, missing_rate \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m\t\u001b[49m\u001b[43msports\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mmissing_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmissing_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# if self.missing_mode == 'camera':\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# \ttime_gap = time_interval(mask, list(range(seq_len)), mode = 'camera')\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# \tmask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0) # [1, time, n_players]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# \tmask = torch.repeat_interleave(mask, self.n_features, dim=-1).expand(bs, -1, -1)  # [bs, time, x_dim]\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# \ttime_gap = torch.repeat_interleave(time_gap, self.n_features, dim=-1).expand(bs, -1, -1)  # [bs, time, x_dim]\u001b[39;00m\n\u001b[1;32m    201\u001b[0m time_gap \u001b[38;5;241m=\u001b[39m time_interval(mask, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(seq_len)), mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/hybrid-imputation/models/utils.py:134\u001b[0m, in \u001b[0;36mgenerate_mask\u001b[0;34m(data, sports, mode, missing_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((player_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], player_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], n_players))  \u001b[38;5;66;03m# [bs, time, players]\u001b[39;00m\n\u001b[1;32m    133\u001b[0m missing_frames \u001b[38;5;241m=\u001b[39m (valid_frames \u001b[38;5;241m*\u001b[39m missing_rate)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# [bs], number of missing values per player\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m start_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, valid_frames \u001b[38;5;241m-\u001b[39m \u001b[43mmissing_len\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    135\u001b[0m end_idxs \u001b[38;5;241m=\u001b[39m start_idxs \u001b[38;5;241m+\u001b[39m missing_len\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'missing_len' referenced before assignment"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = [310, 320, 330, 331, 332, 220, 341, 342]\n",
    "# trial_ids = [i for i in range(1358, 1364)]\n",
    "trial_ids = [1360, 1361]\n",
    "# mode = ['camera', 'playerwise', 'playerwise', 'playerwise', 'uniform', 'uniform', 'uniform']\n",
    "mode = ['playerwise', 'uniform']\n",
    "\n",
    "for idx, trial in enumerate(trial_ids):\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    team_size_dict = {\"soccer\": 11, \"basketball\": 5, \"football\": 3}\n",
    "    model.params['team_size'] = team_size_dict[model.dataset]\n",
    "    model.params['window_size'] = 200\n",
    "    model.params['missing_pattern'] = mode[idx]\n",
    "    model.params['missing_rate'] = 0.5\n",
    "    model.missing_mode = mode[idx]\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: latentode\n",
      "- Compute stats for naive baselines: True\n",
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n",
      "\n",
      "---------- Trial 1361 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2:   0%|                                 | 0/10 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  10%|██▌                      | 1/10 [00:00<00:06,  1.33it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  20%|█████                    | 2/10 [00:02<00:09,  1.16s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  30%|███████▌                 | 3/10 [00:03<00:09,  1.38s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  40%|██████████               | 4/10 [00:04<00:06,  1.11s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  50%|████████████▌            | 5/10 [00:06<00:07,  1.41s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  70%|█████████████████▌       | 7/10 [00:07<00:02,  1.02it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  80%|████████████████████     | 8/10 [00:08<00:01,  1.02it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2:  90%|██████████████████████▌  | 9/10 [00:11<00:01,  1.47s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 2: 100%|████████████████████████| 10/10 [00:12<00:00,  1.24s/it]\n",
      "Phase 3:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 3:  50%|█████████████             | 1/2 [00:00<00:00,  2.16it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 3: 100%|██████████████████████████| 2/2 [00:01<00:00,  1.52it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6:   0%|                                  | 0/1 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 6: 100%|██████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Phase 7:   0%|                                  | 0/2 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 7:  50%|█████████████             | 1/2 [00:01<00:01,  1.04s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 7: 100%|██████████████████████████| 2/2 [00:02<00:00,  1.01s/it]\n",
      "Phase 8:   0%|                                  | 0/3 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8:  33%|████████▋                 | 1/3 [00:01<00:02,  1.44s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.67s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 8: 100%|██████████████████████████| 3/3 [00:03<00:00,  1.24s/it]\n",
      "Phase 9:   0%|                                  | 0/4 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  25%|██████▌                   | 1/4 [00:00<00:02,  1.24it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  50%|█████████████             | 2/4 [00:02<00:02,  1.13s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9:  75%|███████████████████▌      | 3/4 [00:04<00:01,  1.60s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 9: 100%|██████████████████████████| 4/4 [00:06<00:00,  1.55s/it]\n",
      "Phase 10:   0%|                                 | 0/6 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  17%|████▏                    | 1/6 [00:01<00:07,  1.51s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  33%|████████▎                | 2/6 [00:01<00:03,  1.21it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  50%|████████████▌            | 3/6 [00:02<00:02,  1.22it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  67%|████████████████▋        | 4/6 [00:03<00:01,  1.31it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10:  83%|████████████████████▊    | 5/6 [00:03<00:00,  1.40it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 10: 100%|█████████████████████████| 6/6 [00:04<00:00,  1.20it/s]\n",
      "Phase 11:   0%|                                 | 0/7 [00:00<?, ?it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  14%|███▌                     | 1/7 [00:01<00:06,  1.02s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  29%|███████▏                 | 2/7 [00:01<00:03,  1.53it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  43%|██████████▋              | 3/7 [00:02<00:03,  1.22it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  57%|██████████████▎          | 4/7 [00:03<00:03,  1.08s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  71%|█████████████████▊       | 5/7 [00:04<00:01,  1.20it/s]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11:  86%|█████████████████████▍   | 6/7 [00:05<00:01,  1.07s/it]/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n",
      "Phase 11: 100%|█████████████████████████| 7/7 [00:07<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size: 200\n",
      "Missing pattern: uniform\n",
      "Missing rate: 0.4995\n",
      "pred      20.710135\n",
      "linear     4.172049\n",
      "Name: pe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = [310, 320, 330, 331, 332, 220, 341, 342]\n",
    "# trial_ids = [i for i in range(1358, 1364)]\n",
    "trial_ids = [1361]\n",
    "# mode = ['camera', 'playerwise', 'playerwise', 'playerwise', 'uniform', 'uniform', 'uniform']\n",
    "mode = ['uniform']\n",
    "\n",
    "for idx, trial in enumerate(trial_ids):\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    team_size_dict = {\"soccer\": 11, \"basketball\": 5, \"football\": 3}\n",
    "    model.params['team_size'] = team_size_dict[model.dataset]\n",
    "    model.params['window_size'] = 200\n",
    "    model.params['missing_pattern'] = mode[idx]\n",
    "    model.params['missing_rate'] = 0.5\n",
    "    model.missing_mode = mode[idx]\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 1358 ----------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n---------- Trial {trial} ----------\")\n",
    "\n",
    "pred_keys = [\"pred\"]\n",
    "if model_type == \"dbhp\":\n",
    "    if model.params[\"deriv_accum\"]:\n",
    "        pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "    if model.params[\"dynamic_hybrid\"]:\n",
    "        pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "if naive_baselines:\n",
    "    pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "stats = {k: 0 for k in stat_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    }
   ],
   "source": [
    "path = test_data_paths[0]\n",
    "print()\n",
    "print(f\"{path}:\")\n",
    "match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "helper = trace_helper(traces=match_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = helper.team1_players + helper.team2_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "model_type = model.params[\"model\"]\n",
    "random.seed(1000)\n",
    "\n",
    "feature_types = [\"_x\", \"_y\", \"_vx\", \"_vy\", \"_ax\", \"_ay\"][: model.params[\"n_features\"]]\n",
    "\n",
    "players = helper.team1_players + helper.team2_players\n",
    "player_cols = [f\"{p}{x}\" for p in players for x in feature_types]\n",
    "\n",
    "pred_keys = [\"pred\"]\n",
    "if model_type == \"dbhp\":\n",
    "    if model.params[\"deriv_accum\"]:\n",
    "        pred_keys += [\"dap_f\", \"dap_b\"]\n",
    "    if model.params[\"dynamic_hybrid\"]:\n",
    "        pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "if naive_baselines:\n",
    "    pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "\n",
    "stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "# initialize resulting DataFrames\n",
    "ret = dict()\n",
    "ret[\"target\"] = helper.traces.copy(deep=True)\n",
    "ret[\"mask\"] = pd.DataFrame(-1, index=helper.traces.index, columns=player_cols)\n",
    "for k in pred_keys:\n",
    "    ret[k] = helper.traces.copy(deep=True)\n",
    "\n",
    "if model_type == \"dbhp\" and model.params[\"dynamic_hybrid\"]:\n",
    "    lambda_cols = [f\"{p}{w}\" for p in players for w in [\"_w0\", \"_w1\", \"_w2\"]]\n",
    "    ret[\"lambdas\"] = pd.DataFrame(-1, index=helper.traces.index, columns=lambda_cols)\n",
    "\n",
    "x_cols = [c for c in helper.traces.columns if c.endswith(\"_x\")]\n",
    "y_cols = [c for c in helper.traces.columns if c.endswith(\"_y\")]\n",
    "\n",
    "if model.params[\"normalize\"]:\n",
    "    helper.traces[x_cols] /= helper.pitch_size[0]\n",
    "    helper.traces[y_cols] /= helper.pitch_size[1]\n",
    "    helper.pitch_size = (1, 1)\n",
    "\n",
    "for phase in helper.traces[\"phase\"].unique():\n",
    "    phase_traces = helper.traces[helper.traces[\"phase\"] == phase]\n",
    "\n",
    "    phase_gks = SportsDataset.detect_goalkeepers(phase_traces)\n",
    "    team1_code, team2_code = phase_gks[0][0], phase_gks[1][0]\n",
    "\n",
    "    phase_player_cols = phase_traces[player_cols].dropna(axis=1).columns\n",
    "    team1_cols = [c for c in phase_player_cols if c.startswith(team1_code)]\n",
    "    team2_cols = [c for c in phase_player_cols if c.startswith(team2_code)]\n",
    "    ball_cols = [\"ball_x\", \"ball_y\"]\n",
    "\n",
    "    # reorder teams so that the left team comes first\n",
    "    phase_player_cols = team1_cols + team2_cols\n",
    "\n",
    "    if min(len(team1_cols), len(team2_cols)) < model.params[\"n_features\"] * model.params[\"team_size\"]:\n",
    "        continue\n",
    "\n",
    "    episodes = [e for e in phase_traces[\"episode\"].unique() if e > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = episodes[0]\n",
    "min_episode_size=100\n",
    "\n",
    "ep_traces = phase_traces[phase_traces[\"episode\"] == e]\n",
    "if len(ep_traces) < min_episode_size:\n",
    "    print('error')\n",
    "\n",
    "ep_player_traces = torch.FloatTensor(ep_traces[phase_player_cols].values)\n",
    "ep_ball_traces = torch.FloatTensor(ep_traces[ball_cols].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "                    ep_ret, ep_stats = TraceHelper.predict_episode(\n",
    "                        model,\n",
    "                        dataset_type,\n",
    "                        ep_player_traces,\n",
    "                        ep_ball_traces,\n",
    "                        pred_keys=pred_keys,\n",
    "                        window_size=model.params[\"window_size\"],\n",
    "                        min_window_size=min_episode_size,\n",
    "                        naive_baselines=naive_baselines,\n",
    "                        gap_models=gap_models,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = sports\n",
    "window_size=model.params[\"window_size\"]\n",
    "min_window_size=min_episode_size\n",
    "\n",
    "model_type = model.params[\"model\"]\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "player_traces = ep_player_traces.unsqueeze(0).to(device)  # [1, time, x]\n",
    "# target_traces = input_traces.clone()\n",
    "if dataset_type == \"soccer\":\n",
    "    ball_traces = ep_ball_traces.unsqueeze(0).to(device)  # [1, time, 2]\n",
    "\n",
    "if dataset_type == \"afootball\":\n",
    "    out_dim = model.params[\"team_size\"] * model.params[\"n_features\"]\n",
    "    out_xy_dim = model.params[\"team_size\"] * 2\n",
    "else:\n",
    "    out_dim = 2 * model.params[\"team_size\"] * model.params[\"n_features\"]\n",
    "    out_xy_dim = 2 * model.params[\"team_size\"] * 2\n",
    "\n",
    "seq_len = player_traces.shape[1]\n",
    "\n",
    "ret = dict()\n",
    "ret[\"input\"] = torch.zeros(seq_len, out_dim)\n",
    "ret[\"target\"] = torch.zeros(seq_len, out_dim)\n",
    "ret[\"mask\"] = -torch.ones(seq_len, out_dim)\n",
    "\n",
    "for k in pred_keys:\n",
    "    if k == \"pred\":\n",
    "        ret[\"pred\"] = torch.zeros(seq_len, out_dim)  # [time, players * feats]\n",
    "    else:\n",
    "        ret[k] = torch.zeros(seq_len, out_xy_dim)  # [time, players * 2]\n",
    "\n",
    "if model_type == \"dbhp\" and model.params[\"dynamic_hybrid\"]:\n",
    "    if dataset_type == \"afootball\":\n",
    "        ret[\"lambdas\"] = torch.zeros(seq_len, model.params[\"team_size\"] * 3)\n",
    "    else:\n",
    "        ret[\"lambdas\"] = torch.zeros(seq_len, (model.params[\"team_size\"] * 2) * 3)\n",
    "\n",
    "# if model.params[\"missing_pattern\"] == \"camera\":\n",
    "#     n_windows = 1\n",
    "\n",
    "if player_traces.shape[1] % window_size < min_window_size:\n",
    "    n_windows = player_traces.shape[1] // window_size\n",
    "else:\n",
    "    n_windows = player_traces.shape[1] // window_size + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "i_from = window_size * i\n",
    "i_to = window_size * (i + 1) if i < n_windows - 1 else player_traces.shape[1]\n",
    "\n",
    "window_player_traces = player_traces[:, i_from:i_to]\n",
    "if dataset_type == \"soccer\":  # For simulated camera view\n",
    "    window_ball_traces = ball_traces[:, i_from:i_to]\n",
    "\n",
    "# Run model\n",
    "if dataset_type == \"soccer\":\n",
    "    window_inputs = [window_player_traces, window_ball_traces]\n",
    "else:\n",
    "    window_inputs = [window_player_traces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(window_inputs) == 2: #Soccer \n",
    "    x, ball = window_inputs\n",
    "else:\n",
    "    x = window_inputs[0]\n",
    "    ball = []\n",
    "\n",
    "\n",
    "input_dict = {\"target\" : x, \"ball\" : ball}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = dict()\n",
    "bs, seq_len, feat_dim = x.shape\n",
    "x = x.to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_players, _ = get_dataset_config(sports)\n",
    "player_data = input_dict[\"target\"]  # [bs, time, players * feats]\n",
    "\n",
    "# compute the length of each sequence without padding\n",
    "if player_data.is_cuda:\n",
    "    valid_frames = np.array(player_data.cpu()[..., 0] != -100).astype(int).sum(axis=-1)  # [bs]\n",
    "else:\n",
    "    valid_frames = np.array(player_data[..., 0] != -100).astype(int).sum(axis=-1)  # [bs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data, ball_data = input_dict[\"target\"].clone().cpu(), input_dict[\"ball\"].clone().cpu()\n",
    "player_pos = reshape_tensor(player_data, upscale=True, dataset_type=sports)  # [bs, time, players, 2]\n",
    "ball_pos = normalize_tensor(ball_data, mode=\"upscale\", dataset_type=sports)\n",
    "\n",
    "if player_data.is_cuda:\n",
    "    is_pad = np.array(player_data.cpu()[..., :1] == -100).astype(int)\n",
    "else:\n",
    "    is_pad = np.array(player_data[..., :1] == -100).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_vertices = compute_camera_coverage(ball_pos)\n",
    "mask = is_inside(camera_vertices, player_pos)  # [bs, time, players]\n",
    "mask = (1 - is_pad) * mask + is_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[:, :5, :] = 1\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i, valid_frames[i] - 5 :] = 1\n",
    "\n",
    "missing_rate = ((1 - is_pad) * (1 - mask)).sum() / ((1 - is_pad).sum() * n_players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200, 22)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'camera'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.missing_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 132]) torch.Size([1, 200, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/mhlee7227/hybrid-imputation/models/latentode/latent_ode.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  time_gap = torch.tensor(time_gap, dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "window_ret = model.forward(window_inputs, mode=\"test\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_config(dataset):\n",
    "    \"\"\"\n",
    "    players : number of total players contained each dataset\n",
    "    ps : (width, height) pitch sizes\n",
    "    \"\"\"\n",
    "    if dataset == \"soccer\":\n",
    "        players = 22\n",
    "        ps = (108, 72)\n",
    "    elif dataset == \"basketball\":\n",
    "        players = 10\n",
    "        ps = (28.65, 15.24)\n",
    "    elif dataset == \"afootball\":\n",
    "        players = 6\n",
    "        ps = (110, 49)\n",
    "        # ps = (1, 1)\n",
    "\n",
    "    return players, ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"model\"] == \"nrtsi\":\n",
    "    match_ret, match_stats = helper.predict(\n",
    "        model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "    )\n",
    "else:\n",
    "    match_ret, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "\n",
    "for k, v in match_stats.items():\n",
    "    stats[k] += v\n",
    "\n",
    "# print(\"Total Performance:\")\n",
    "# print_helper(ret, pred_keys, trial=trial, save_txt=True)\n",
    "\n",
    "# torch.save(helper, f\"{save_path}/helper\")\n",
    "# torch.save(ret, f\"{save_path}/df_dict\")\n",
    "\n",
    "n_players, _ = get_dataset_config(sports)\n",
    "stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "for k, v in stats.items():\n",
    "if k in [\"total_frames\", \"missing_frames\"]:\n",
    "    continue\n",
    "\n",
    "pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "metric = k.split(\"_\")[-1]\n",
    "\n",
    "if metric in [\"pe\", \"se\"]:\n",
    "    stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "    \n",
    "elif metric in [\"sce\", \"ple\"]:\n",
    "    stats[k] = round(v / (stats[\"total_frames\"] * n_players), 6)\n",
    "\n",
    "stats_df.at[pred_key, metric] = stats[k]\n",
    "\n",
    "# print(f\"Total frames: {stats['total_frames'] * n_players}\")\n",
    "# print(f\"Missing frames: {stats['missing_frames']}\")\n",
    "print()\n",
    "print(f\"Window size: {params['window_size']}\")\n",
    "print(f\"Missing pattern: {params['missing_pattern']}\")\n",
    "print(f\"Missing rate: {stats['missing_frames'] / (stats['total_frames'] * n_players):.4f}\")\n",
    "print(stats_df.loc[[\"pred\", \"dap_f\", \"dap_b\", \"hybrid_s2\", \"hybrid_d\", \"linear\"], \"pe\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on window size and missing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 205 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.07it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:02<00:00,  2.06it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size: 50\n",
      "Missing pattern: playerwise\n",
      "Missing rate: 0.9000\n",
      "pred         5.267954\n",
      "dap_f        1.723606\n",
      "dap_b        1.748702\n",
      "hybrid_s2     0.54647\n",
      "hybrid_d     0.477616\n",
      "linear       1.501628\n",
      "Name: pe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = np.sort([int(i) for i in os.listdir(\"saved\") if int(i) >= 200 and int(i) < 250])\n",
    "trial_ids = [205]\n",
    "\n",
    "for trial in trial_ids:\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 253, 132])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = helper\n",
    "ep_traces = self.traces[helper.traces[\"episode\"] == 36]\n",
    "\n",
    "feature_types = [\"_x\", \"_y\", \"_vx\", \"_vy\", \"_ax\", \"_ay\"]\n",
    "players = self.team1_players + self.team2_players\n",
    "player_cols = [f\"{p}{x}\" for p in players for x in feature_types]\n",
    "\n",
    "phase_gks = SportsDataset.detect_goalkeepers(ep_traces)\n",
    "team1_code, team2_code = phase_gks[0][0], phase_gks[1][0]\n",
    "\n",
    "ep_player_cols = ep_traces[player_cols].dropna(axis=1).columns\n",
    "team1_cols = [c for c in ep_player_cols if c.startswith(team1_code)]\n",
    "team2_cols = [c for c in ep_player_cols if c.startswith(team2_code)]\n",
    "ball_cols = [\"ball_x\", \"ball_y\"]\n",
    "\n",
    "ep_player_cols = team1_cols + team2_cols\n",
    "ep_player_traces = torch.FloatTensor(ep_traces[ep_player_cols].values).unsqueeze(0)\n",
    "ep_player_traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6058, 1.0526, 0.8447, 0.5932, 1.2615, 0.9120, 0.8317, 0.9120, 1.1420,\n",
       "        0.7295, 0.7110, 1.4746, 1.0250, 1.2611, 1.5325, 0.9509, 1.1192, 1.3261,\n",
       "        1.2470, 0.8331, 0.9942, 1.0473])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = ep_player_traces.shape[:2]\n",
    "tensor = ep_player_traces.reshape(bs, seq_len, 22, -1)\n",
    "\n",
    "x = tensor[..., 0:1]  # [bs, time, players, 1]\n",
    "y = tensor[..., 1:2]\n",
    "xy = torch.cat([x, y], dim=-1)  # [bs, time, players, 2]\n",
    "\n",
    "x_plus_y = torch.sum(xy, dim=-1)  # [bs, time, players]\n",
    "\n",
    "sorted_tensor = tensor.clone()\n",
    "sort_idxs = torch.zeros(bs, n_players, dtype=int)\n",
    "\n",
    "x_plus_y[0, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Get Main model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 3003\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "if os.path.isfile(save_path + \"/df_dict\"):\n",
    "    helper =  torch.load(save_path + \"/helper\")\n",
    "    df_dict = torch.load(save_path + \"/df_dict\")\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Add baseline model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_dict = {4000 : \"brits\", 5000 : \"naomi\", 214 : \"nrtsi\"} # Metrica\n",
    "trial_dict = {4003 : \"brits\", 5001 : \"naomi\", 6001 : \"nrtsi\", 9996 : \"graphimputer\"} # NBA\n",
    "for (t, model_type) in trial_dict.items():\n",
    "    save_path = f\"saved/{t:03d}\"\n",
    "    if os.path.isfile(save_path + \"/df_dict\"):\n",
    "        df_dict_ = torch.load(save_path + \"/df_dict\")\n",
    "        df_dict[f\"{model_type}_df\"] = df_dict_[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Soccer Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.traces[\"episode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 479\n",
    "i1 = 873\n",
    "\n",
    "animator = TraceAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    mask = df_dict[\"mask\"][i0:i1],\n",
    "    show_episodes=True,\n",
    "    show_events=False,\n",
    "    show_frames=False,\n",
    "    show_polygon=True,\n",
    "    annot_cols=None,\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Basketball Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 326\n",
    "i1 = 737\n",
    "animator = NBADataAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    show_episodes=True,\n",
    "    show_frames=True,\n",
    "    masks = df_dict[\"mask\"][i0:i1],\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = \"imputed_traj\" # \"imputed_traj\", \"dist_heatmap\", \"weights_heatmap\"\n",
    "sports = params[\"dataset\"]\n",
    "visualizer = VisualizeHelper(trial, df_dict, plot_mode, dataset=sports, helper=helper)\n",
    "visualizer.valid_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_run(epi_idx=0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c44ecce01b6920a996c2e45a7791c773f725b79a727cce05b077a0ad48ece758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
