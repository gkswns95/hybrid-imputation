{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from dataset import SportsDataset\n",
    "from datatools.trace_animator import TraceAnimator\n",
    "from datatools.trace_helper import TraceHelper\n",
    "from datatools.visualize_helper import VisualizeHelper\n",
    "from datatools.nba_helper import NBADataHelper, NBADataAnimator\n",
    "from datatools.nfl_helper import NFLDataHelper\n",
    "from models import load_model\n",
    "from models.utils import get_dataset_config, print_helper, reshape_tensor, sort_players\n",
    "\n",
    "from models.graph_imputer.graph_imputer import BidirectionalGraphImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluating on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial = 400\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"model\"] == \"nrtsi\":\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "\n",
    "    gap_models = dict()\n",
    "    gap_models[1] = f\"{save_path}/model/nrtsi_state_dict_best_gap_1.pt\"\n",
    "    gap_models[2] = f\"{save_path}/model/nrtsi_state_dict_best_gap_2.pt\"\n",
    "    gap_models[4] = f\"{save_path}/model/nrtsi_state_dict_best_gap_4.pt\"\n",
    "    gap_models[8] = f\"{save_path}/model/nrtsi_state_dict_best_gap_8.pt\"\n",
    "    gap_models[16] = f\"{save_path}/model/nrtsi_state_dict_best_gap_16.pt\"\n",
    "\n",
    "    for k in gap_models:\n",
    "        gap_models[k] = torch.load(gap_models[k], map_location=lambda storage, _: storage)\n",
    "else:\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: soccer\n",
      "- Model type: dbhp\n",
      "- Compute stats for naive baselines: True\n"
     ]
    }
   ],
   "source": [
    "sports = params[\"dataset\"]\n",
    "model_type = params[\"model\"]\n",
    "naive_baselines = True\n",
    "\n",
    "if model_type == \"dbhp\":\n",
    "    deriv_accum = params[\"deriv_accum\"]\n",
    "    dynamic_hybrid = params[\"dynamic_hybrid\"]\n",
    "\n",
    "print(f\"- Sports: {sports}\")\n",
    "print(f\"- Model type: {model_type}\")\n",
    "print(f\"- Compute stats for naive baselines: {naive_baselines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data paths: ['data/metrica_traces/match3_test.csv']\n"
     ]
    }
   ],
   "source": [
    "metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "nba_files = os.listdir(\"data/nba_traces\")\n",
    "nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "nba_paths.sort()\n",
    "\n",
    "nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "nfl_paths.sort()\n",
    "\n",
    "if sports == \"soccer\":\n",
    "    trace_helper = TraceHelper\n",
    "    test_data_paths = metrica_paths[3:4]\n",
    "elif sports == \"basketball\":\n",
    "    trace_helper = NBADataHelper\n",
    "    test_data_paths = nba_paths[90:]\n",
    "else: # e.g. \"American football\"\n",
    "    trace_helper = NFLDataHelper\n",
    "    test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "print(f\"Test data paths: {test_data_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(687, 249474)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = nba_paths[70:80]\n",
    "n_episodes = 0\n",
    "n_frames = 0\n",
    "\n",
    "for f in tqdm(paths):\n",
    "    match_traces = pd.read_csv(f, header=0)\n",
    "    episodes = [e for e in match_traces[\"episode\"].unique() if e > 0]\n",
    "    for e in episodes:\n",
    "        ep_traces = match_traces[match_traces[\"episode\"] == e]\n",
    "        if len(ep_traces) >= 100:\n",
    "            n_episodes += 1\n",
    "            n_frames += len(ep_traces)\n",
    "\n",
    "n_episodes, n_frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for testing a trial and printing performance statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(trial, model, params, sports=\"soccer\", naive_baselines=True):\n",
    "    print(f\"\\n---------- Trial {trial} ----------\")\n",
    "\n",
    "    pred_keys = [\"pred\"]\n",
    "    if model_type == \"dbhp\":\n",
    "        if model.params[\"deriv_accum\"]:\n",
    "            pred_keys += [\"dap_f\"]\n",
    "            if model.params[\"missing_pattern\"] != \"forecast\":\n",
    "                pred_keys += [\"dap_b\"]\n",
    "        if model.params[\"dynamic_hybrid\"]:\n",
    "            if model.params[\"missing_pattern\"] == \"forecast\":\n",
    "                pred_keys += [\"hybrid_d\"]\n",
    "            else:\n",
    "                pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "    if naive_baselines:\n",
    "        if model.params[\"missing_pattern\"] == \"forecast\":\n",
    "            pred_keys += [\"ffill\"]\n",
    "        else:\n",
    "            pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "    stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "    stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "    stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "    for path in test_data_paths:\n",
    "        print()\n",
    "        print(f\"{path}:\")\n",
    "        match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "        helper = trace_helper(traces=match_traces)\n",
    "\n",
    "        if params[\"model\"] == \"nrtsi\":\n",
    "            _, match_stats = helper.predict(\n",
    "                model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "            )\n",
    "        else:\n",
    "            _, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "\n",
    "        for k, v in match_stats.items():\n",
    "            stats[k] += v\n",
    "\n",
    "    n_players, _ = get_dataset_config(sports)\n",
    "    stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "    for k, v in stats.items():\n",
    "        if k in [\"total_frames\", \"missing_frames\"]:\n",
    "            continue\n",
    "        \n",
    "        pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "        metric = k.split(\"_\")[-1]\n",
    "\n",
    "        if metric in [\"pe\", \"se\"]:\n",
    "            stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "            \n",
    "        elif metric in [\"sce\", \"ple\"]:\n",
    "            stats[k] = round(v / (stats[\"total_frames\"] * n_players), 6)\n",
    "\n",
    "        stats_df.at[pred_key, metric] = stats[k]\n",
    "    \n",
    "    params[\"missing_rate\"] = round(stats['missing_frames'] / (stats['total_frames'] * n_players), 4)\n",
    "\n",
    "    print()\n",
    "    print_args = pd.Series(dtype=object)\n",
    "    for arg in [\"window_size\", \"missing_pattern\", \"missing_rate\"]:\n",
    "        print_args[arg] = params[arg]\n",
    "    print(print_args)\n",
    "    \n",
    "    print()\n",
    "    if params[\"missing_pattern\"] == \"forecast\":\n",
    "        print(stats_df.loc[[\"pred\", \"dap_f\", \"hybrid_d\", \"ffill\"], \"pe\"])\n",
    "    else:\n",
    "        print(stats_df.loc[[\"pred\", \"dap_f\", \"dap_b\", \"hybrid_s2\", \"hybrid_d\", \"linear\"], \"pe\"])\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on Set Transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 150 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.61it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         4.000079\n",
      "dap_f        2.820311\n",
      "dap_b        2.826135\n",
      "hybrid_s2    2.559717\n",
      "hybrid_d     2.554931\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n",
      "\n",
      "---------- Trial 153 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  3.38it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.22it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         1.659995\n",
      "dap_f        1.574153\n",
      "dap_b        1.558952\n",
      "hybrid_s2    1.407736\n",
      "hybrid_d     1.402515\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n",
      "\n",
      "---------- Trial 152 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  3.58it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.47it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         1.671272\n",
      "dap_f        1.498494\n",
      "dap_b        1.559472\n",
      "hybrid_s2     1.28217\n",
      "hybrid_d     1.264403\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n",
      "\n",
      "---------- Trial 160 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  4.20it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.38it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         2.911883\n",
      "dap_f         2.69725\n",
      "dap_b        2.685772\n",
      "hybrid_s2     2.51763\n",
      "hybrid_d     2.495356\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n",
      "\n",
      "---------- Trial 161 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:04<00:00,  2.47it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  4.35it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.88it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  2.44it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.50it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         1.623484\n",
      "dap_f        1.573099\n",
      "dap_b        1.566982\n",
      "hybrid_s2    1.408237\n",
      "hybrid_d     1.401323\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n",
      "\n",
      "---------- Trial 220 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:03<00:00,  2.57it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:00<00:00,  4.23it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Phase 7: 100%|██████████| 2/2 [00:00<00:00,  2.87it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:01<00:00,  2.42it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
      "Phase 10: 100%|██████████| 6/6 [00:01<00:00,  3.51it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size           200\n",
      "missing_pattern    camera\n",
      "missing_rate       0.5375\n",
      "dtype: object\n",
      "\n",
      "pred         1.530029\n",
      "dap_f         1.46189\n",
      "dap_b        1.442525\n",
      "hybrid_s2    1.273535\n",
      "hybrid_d     1.263453\n",
      "linear       3.166009\n",
      "Name: pe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "trial_ids = [150, 153, 152, 160, 161, 220]\n",
    "\n",
    "for trial in trial_ids:\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on window size and missing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evolvegraph: multi-agent trajectory prediction with dynamic relational reasoning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 205 ----------\n",
      "\n",
      "data/metrica_traces/match3_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: 100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n",
      "Phase 3: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "Phase 4: 0it [00:00, ?it/s]\n",
      "Phase 5: 0it [00:00, ?it/s]\n",
      "Phase 6: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Phase 7: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "Phase 8: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "Phase 9: 100%|██████████| 4/4 [00:04<00:00,  1.07s/it]\n",
      "Phase 10: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Phase 11: 100%|██████████| 7/7 [00:03<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window size: 50\n",
      "Missing pattern: playerwise\n",
      "Missing rate: 0.9000\n",
      "pred         5.799402\n",
      "dap_f        1.852439\n",
      "dap_b        1.931425\n",
      "hybrid_s2    0.568018\n",
      "hybrid_d     0.503865\n",
      "linear       1.502152\n",
      "Name: pe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = np.sort([int(i) for i in os.listdir(\"saved\") if int(i) >= 200 and int(i) < 250])\n",
    "trial_ids = [205]\n",
    "\n",
    "for trial in trial_ids:\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 253, 132])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = helper\n",
    "ep_traces = self.traces[helper.traces[\"episode\"] == 36]\n",
    "\n",
    "feature_types = [\"_x\", \"_y\", \"_vx\", \"_vy\", \"_ax\", \"_ay\"]\n",
    "players = self.team1_players + self.team2_players\n",
    "player_cols = [f\"{p}{x}\" for p in players for x in feature_types]\n",
    "\n",
    "phase_gks = SportsDataset.detect_goalkeepers(ep_traces)\n",
    "team1_code, team2_code = phase_gks[0][0], phase_gks[1][0]\n",
    "\n",
    "ep_player_cols = ep_traces[player_cols].dropna(axis=1).columns\n",
    "team1_cols = [c for c in ep_player_cols if c.startswith(team1_code)]\n",
    "team2_cols = [c for c in ep_player_cols if c.startswith(team2_code)]\n",
    "ball_cols = [\"ball_x\", \"ball_y\"]\n",
    "\n",
    "ep_player_cols = team1_cols + team2_cols\n",
    "ep_player_traces = torch.FloatTensor(ep_traces[ep_player_cols].values).unsqueeze(0)\n",
    "ep_player_traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6058, 1.0526, 0.8447, 0.5932, 1.2615, 0.9120, 0.8317, 0.9120, 1.1420,\n",
       "        0.7295, 0.7110, 1.4746, 1.0250, 1.2611, 1.5325, 0.9509, 1.1192, 1.3261,\n",
       "        1.2470, 0.8331, 0.9942, 1.0473])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, seq_len = ep_player_traces.shape[:2]\n",
    "tensor = ep_player_traces.reshape(bs, seq_len, 22, -1)\n",
    "\n",
    "x = tensor[..., 0:1]  # [bs, time, players, 1]\n",
    "y = tensor[..., 1:2]\n",
    "xy = torch.cat([x, y], dim=-1)  # [bs, time, players, 2]\n",
    "\n",
    "x_plus_y = torch.sum(xy, dim=-1)  # [bs, time, players]\n",
    "\n",
    "sorted_tensor = tensor.clone()\n",
    "sort_idxs = torch.zeros(bs, n_players, dtype=int)\n",
    "\n",
    "x_plus_y[0, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Get Main model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 3003\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "if os.path.isfile(save_path + \"/df_dict\"):\n",
    "    helper =  torch.load(save_path + \"/helper\")\n",
    "    df_dict = torch.load(save_path + \"/df_dict\")\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Add baseline model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_dict = {4000 : \"brits\", 5000 : \"naomi\", 214 : \"nrtsi\"} # Metrica\n",
    "trial_dict = {4003 : \"brits\", 5001 : \"naomi\", 6001 : \"nrtsi\", 9996 : \"graphimputer\"} # NBA\n",
    "for (t, model_type) in trial_dict.items():\n",
    "    save_path = f\"saved/{t:03d}\"\n",
    "    if os.path.isfile(save_path + \"/df_dict\"):\n",
    "        df_dict_ = torch.load(save_path + \"/df_dict\")\n",
    "        df_dict[f\"{model_type}_df\"] = df_dict_[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Soccer Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.traces[\"episode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 479\n",
    "i1 = 873\n",
    "\n",
    "animator = TraceAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    mask = df_dict[\"mask\"][i0:i1],\n",
    "    show_episodes=True,\n",
    "    show_events=False,\n",
    "    show_frames=False,\n",
    "    show_polygon=True,\n",
    "    annot_cols=None,\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Basketball Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 326\n",
    "i1 = 737\n",
    "animator = NBADataAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target\"][i0:i1], \"pred\": df_dict[\"dbhp_df\"][i0:i1]},\n",
    "    show_episodes=True,\n",
    "    show_frames=True,\n",
    "    masks = df_dict[\"mask\"][i0:i1],\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = \"imputed_traj\" # \"imputed_traj\", \"dist_heatmap\", \"weights_heatmap\"\n",
    "sports = params[\"dataset\"]\n",
    "visualizer = VisualizeHelper(trial, df_dict, plot_mode, dataset=sports, helper=helper)\n",
    "visualizer.valid_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_run(epi_idx=0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c44ecce01b6920a996c2e45a7791c773f725b79a727cce05b077a0ad48ece758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
