{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from dataset import SportsDataset\n",
    "from datatools.trace_animator import TraceAnimator\n",
    "from datatools.trace_helper import TraceHelper\n",
    "from datatools.visualize_helper import VisualizeHelper\n",
    "from datatools.nba_helper import NBADataHelper, NBADataAnimator\n",
    "from datatools.nfl_helper import NFLDataHelper\n",
    "from models import load_model\n",
    "from models.utils import get_dataset_config, print_helper, reshape_tensor, sort_players\n",
    "\n",
    "from models.graph_imputer.graph_imputer import BidirectionalGraphImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluating on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial = 420\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"model\"] == \"nrtsi\":\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "\n",
    "    gap_models = dict()\n",
    "    gap_models[1] = f\"{save_path}/model/nrtsi_state_dict_best_gap_1.pt\"\n",
    "    gap_models[2] = f\"{save_path}/model/nrtsi_state_dict_best_gap_2.pt\"\n",
    "    gap_models[4] = f\"{save_path}/model/nrtsi_state_dict_best_gap_4.pt\"\n",
    "    gap_models[8] = f\"{save_path}/model/nrtsi_state_dict_best_gap_8.pt\"\n",
    "    gap_models[16] = f\"{save_path}/model/nrtsi_state_dict_best_gap_16.pt\"\n",
    "\n",
    "    for k in gap_models:\n",
    "        gap_models[k] = torch.load(gap_models[k], map_location=lambda storage, _: storage)\n",
    "else:\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sports: afootball\n",
      "- Model type: brits\n",
      "- Missing pattern : playerwise\n",
      "- Compute stats for naive baselines: True\n"
     ]
    }
   ],
   "source": [
    "sports = params[\"dataset\"]\n",
    "model_type = params[\"model\"]\n",
    "missing_pattern = params[\"missing_pattern\"]\n",
    "naive_baselines = True\n",
    "\n",
    "if model_type == \"dbhp\":\n",
    "    deriv_accum = params[\"deriv_accum\"]\n",
    "    dynamic_hybrid = params[\"dynamic_hybrid\"]\n",
    "\n",
    "print(f\"- Sports: {sports}\")\n",
    "print(f\"- Model type: {model_type}\")\n",
    "print(f\"- Missing pattern : {missing_pattern}\")\n",
    "print(f\"- Compute stats for naive baselines: {naive_baselines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data paths: ['data/nfl_traces/nfl_test.csv']\n"
     ]
    }
   ],
   "source": [
    "metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "nba_files = os.listdir(\"data/nba_traces\")\n",
    "nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "nba_paths.sort()\n",
    "\n",
    "nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "nfl_paths.sort()\n",
    "\n",
    "if sports == \"soccer\":\n",
    "    trace_helper = TraceHelper\n",
    "    test_data_paths = metrica_paths[3:4]\n",
    "elif sports == \"basketball\":\n",
    "    trace_helper = NBADataHelper\n",
    "    test_data_paths = nba_paths[80:]\n",
    "    # test_data_paths = nba_paths[90:]\n",
    "else: # e.g. \"American football\"\n",
    "    trace_helper = NFLDataHelper\n",
    "    test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "print(f\"Test data paths: {test_data_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = nba_paths[70:80]\n",
    "# n_episodes = 0\n",
    "# n_frames = 0\n",
    "\n",
    "# for f in tqdm(paths):\n",
    "#     match_traces = pd.read_csv(f, header=0)\n",
    "#     episodes = [e for e in match_traces[\"episode\"].unique() if e > 0]\n",
    "#     for e in episodes:\n",
    "#         ep_traces = match_traces[match_traces[\"episode\"] == e]\n",
    "#         if len(ep_traces) >= 100:\n",
    "#             n_episodes += 1\n",
    "#             n_frames += len(ep_traces)\n",
    "\n",
    "# n_episodes, n_frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for testing a trial and printing performance statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(trial, model, params, sports=\"soccer\", naive_baselines=True):\n",
    "    print(f\"\\n---------- Trial {trial} ----------\")\n",
    "\n",
    "    pred_keys = [\"pred\"]\n",
    "    if model_type == \"dbhp\":\n",
    "        if model.params[\"deriv_accum\"]:\n",
    "            pred_keys += [\"dap_f\"]\n",
    "            if model.params[\"missing_pattern\"] != \"forecast\":\n",
    "                pred_keys += [\"dap_b\"]\n",
    "        if model.params[\"dynamic_hybrid\"]:\n",
    "            if model.params[\"missing_pattern\"] == \"forecast\":\n",
    "                pred_keys += [\"hybrid_d\"]\n",
    "            else:\n",
    "                pred_keys += [\"hybrid_s\", \"hybrid_s2\", \"hybrid_d\"]\n",
    "    if naive_baselines:\n",
    "        if model.params[\"missing_pattern\"] == \"forecast\":\n",
    "            pred_keys += [\"ffill\"]\n",
    "        else:\n",
    "            pred_keys += [\"linear\", \"knn\", \"ffill\"]\n",
    "\n",
    "    stat_keys = [\"total_frames\", \"missing_frames\"]\n",
    "    stat_keys += [f\"{k}_{m}\" for k in pred_keys for m in [\"pe\", \"se\", \"sce\", \"ple\"]]\n",
    "    stats = {k: 0 for k in stat_keys}\n",
    "\n",
    "    for path in test_data_paths:\n",
    "        print()\n",
    "        print(f\"{path}:\")\n",
    "        match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "        helper = trace_helper(traces=match_traces)\n",
    "\n",
    "        if params[\"model\"] == \"nrtsi\":\n",
    "            match_ret, match_stats = helper.predict(\n",
    "                model, dataset_type=sports, naive_baselines=naive_baselines, gap_models=gap_models\n",
    "            )\n",
    "        else:\n",
    "            match_ret, match_stats = helper.predict(model, dataset_type=sports, naive_baselines=naive_baselines)\n",
    "\n",
    "        for k, v in match_stats.items():\n",
    "            stats[k] += v\n",
    "\n",
    "    n_players, _ = get_dataset_config(sports)\n",
    "    stats_df = pd.DataFrame(index=pred_keys, columns=[\"pe\", \"se\", \"sce\", \"ple\"])\n",
    "\n",
    "    for k, v in stats.items():\n",
    "        if k in [\"total_frames\", \"missing_frames\"]:\n",
    "            continue\n",
    "        \n",
    "        pred_key = \"_\".join(k.split(\"_\")[:-1])\n",
    "        metric = k.split(\"_\")[-1]\n",
    "\n",
    "        if metric in [\"pe\", \"se\"]:\n",
    "            stats[k] = round(v / stats[\"missing_frames\"], 6)\n",
    "            \n",
    "        elif metric in [\"sce\", \"ple\"]:\n",
    "            scale = 1e+3 if metric == \"sce\" else 1\n",
    "            stats[k] = round(scale * (v / (stats[\"total_frames\"] * n_players)), 8)\n",
    "\n",
    "        stats_df.at[pred_key, metric] = stats[k]\n",
    "    \n",
    "    params[\"missing_rate\"] = round(stats['missing_frames'] / (stats['total_frames'] * n_players), 4)\n",
    "\n",
    "    print()\n",
    "    print_args = pd.Series(dtype=object)\n",
    "    for arg in [\"window_size\", \"missing_pattern\", \"missing_rate\"]:\n",
    "        print_args[arg] = params[arg]\n",
    "    print(print_args)\n",
    "    \n",
    "    # print()\n",
    "    # if params[\"missing_pattern\"] == \"forecast\":\n",
    "    #     print(stats_df.loc[[\"pred\", \"dap_f\", \"hybrid_d\", \"ffill\"], \"pe\"])\n",
    "    # else:\n",
    "    #     print(stats_df.loc[[\"pred\", \"dap_f\", \"dap_b\", \"hybrid_s2\", \"hybrid_d\", \"linear\"], \"pe\"])\n",
    "\n",
    "    return match_ret, stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing imputation performence on a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Trial 420 ----------\n",
      "\n",
      "data/nfl_traces/nfl_test.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 100%|██████████| 1043/1043 [03:32<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window_size                50\n",
      "missing_pattern    playerwise\n",
      "missing_rate              0.5\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "match_ret, stats_df = print_stats(trial, model, params, sports=sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pe</th>\n",
       "      <th>se</th>\n",
       "      <th>sce</th>\n",
       "      <th>ple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>0.075719</td>\n",
       "      <td>0.09818</td>\n",
       "      <td>2.956658</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.13883</td>\n",
       "      <td>0.001269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.027461</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>1.249877</td>\n",
       "      <td>0.006737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffill</th>\n",
       "      <td>0.040813</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>1.993404</td>\n",
       "      <td>0.001269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pe        se       sce       ple\n",
       "pred    0.075719   0.09818  2.956658  0.030814\n",
       "linear  0.021518  0.019028   0.13883  0.001269\n",
       "knn     0.027461  0.060625  1.249877  0.006737\n",
       "ffill   0.040813  0.067451  1.993404  0.001269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on Set Transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial_ids = [150, 153, 152, 160, 161, 220]\n",
    "\n",
    "for trial in trial_ids:\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation study on window size and missing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "# trial_ids = np.sort([int(i) for i in os.listdir(\"saved\") if int(i) >= 200 and int(i) < 250])\n",
    "trial_ids = [205]\n",
    "\n",
    "for trial in trial_ids:\n",
    "    save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print_stats(trial, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = helper\n",
    "ep_traces = self.traces[helper.traces[\"episode\"] == 36]\n",
    "\n",
    "feature_types = [\"_x\", \"_y\", \"_vx\", \"_vy\", \"_ax\", \"_ay\"]\n",
    "players = self.team1_players + self.team2_players\n",
    "player_cols = [f\"{p}{x}\" for p in players for x in feature_types]\n",
    "\n",
    "phase_gks = SportsDataset.detect_goalkeepers(ep_traces)\n",
    "team1_code, team2_code = phase_gks[0][0], phase_gks[1][0]\n",
    "\n",
    "ep_player_cols = ep_traces[player_cols].dropna(axis=1).columns\n",
    "team1_cols = [c for c in ep_player_cols if c.startswith(team1_code)]\n",
    "team2_cols = [c for c in ep_player_cols if c.startswith(team2_code)]\n",
    "ball_cols = [\"ball_x\", \"ball_y\"]\n",
    "\n",
    "ep_player_cols = team1_cols + team2_cols\n",
    "ep_player_traces = torch.FloatTensor(ep_traces[ep_player_cols].values).unsqueeze(0)\n",
    "ep_player_traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len = ep_player_traces.shape[:2]\n",
    "tensor = ep_player_traces.reshape(bs, seq_len, 22, -1)\n",
    "\n",
    "x = tensor[..., 0:1]  # [bs, time, players, 1]\n",
    "y = tensor[..., 1:2]\n",
    "xy = torch.cat([x, y], dim=-1)  # [bs, time, players, 2]\n",
    "\n",
    "x_plus_y = torch.sum(xy, dim=-1)  # [bs, time, players]\n",
    "\n",
    "sorted_tensor = tensor.clone()\n",
    "sort_idxs = torch.zeros(bs, n_players, dtype=int)\n",
    "\n",
    "x_plus_y[0, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Get Main model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 3003\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "if os.path.isfile(save_path + \"/df_dict\"):\n",
    "    helper =  torch.load(save_path + \"/helper\")\n",
    "    df_dict = torch.load(save_path + \"/df_dict\")\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Add baseline model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_dict = {4000 : \"brits\", 5000 : \"naomi\", 214 : \"nrtsi\"} # Metrica\n",
    "trial_dict = {4003 : \"brits\", 5001 : \"naomi\", 6001 : \"nrtsi\", 9996 : \"graphimputer\"} # NBA\n",
    "for (t, model_type) in trial_dict.items():\n",
    "    save_path = f\"saved/{t:03d}\"\n",
    "    if os.path.isfile(save_path + \"/df_dict\"):\n",
    "        df_dict_ = torch.load(save_path + \"/df_dict\")\n",
    "        df_dict[f\"{model_type}_df\"] = df_dict_[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Soccer Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 479\n",
    "i1 = 873\n",
    "\n",
    "animator = TraceAnimator(\n",
    "    match_ret={\"main\": match_ret[\"target\"][i0:i1], \"pred\": match_ret[\"hybrid_d\"][i0:i1]},\n",
    "    mask = match_ret[\"mask\"][i0:i1],\n",
    "    show_episodes=True,\n",
    "    show_events=False,\n",
    "    show_frames=False,\n",
    "    show_polygon=True,\n",
    "    annot_cols=None,\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "if not os.path.exists(\"animations\"):\n",
    "    os.makedirs(\"animations\")\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Basketball Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 326\n",
    "i1 = 737\n",
    "animator = NBADataAnimator(\n",
    "    match_ret={\"main\": match_ret[\"target\"][i0:i1], \"pred\": match_ret[\"hybrid_d\"][i0:i1]},\n",
    "    show_episodes=True,\n",
    "    show_frames=True,\n",
    "    masks = match_ret[\"mask\"][i0:i1],\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "if not os.path.exists(\"animations\"):\n",
    "    os.makedirs(\"animations\")\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing imputed trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = \"imputed_traj\" # \"imputed_traj\", \"dist_heatmap\", \"weights_heatmap\"\n",
    "sports = params[\"dataset\"]\n",
    "visualizer = VisualizeHelper(trial, df_dict, plot_mode, dataset=sports, helper=helper)\n",
    "visualizer.valid_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_run(epi_idx=0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c44ecce01b6920a996c2e45a7791c773f725b79a727cce05b077a0ad48ece758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
