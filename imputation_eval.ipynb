{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import animation\n",
    "from datatools.trace_animator import TraceAnimator\n",
    "from datatools.trace_helper import TraceHelper\n",
    "from datatools.visualize_helper import VisualizeHelper\n",
    "from datatools.nba_helper import NBADataHelper, NBADataAnimator\n",
    "from datatools.nfl_helper import NFLDataHelper\n",
    "\n",
    "from models import load_model\n",
    "from models.utils import print_helper, reshape_tensor, get_dataset_config, normalize_tensor\n",
    "\n",
    "from models.graph_imputer.graph_imputer import BidirectionalGraphImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluating on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "trial = 3012\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "\n",
    "with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"model\"] == \"nrtsi\":\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "\n",
    "    gap_models_dict = dict()\n",
    "\n",
    "    gap_models_dict[1] = f\"{save_path}/model/nrtsi_state_dict_best_gap_1.pt\"\n",
    "    gap_models_dict[2] = f\"{save_path}/model/nrtsi_state_dict_best_gap_2.pt\"\n",
    "    gap_models_dict[4] = f\"{save_path}/model/nrtsi_state_dict_best_gap_4.pt\"\n",
    "    gap_models_dict[8] = f\"{save_path}/model/nrtsi_state_dict_best_gap_8.pt\"\n",
    "    gap_models_dict[16] = f\"{save_path}/model/nrtsi_state_dict_best_gap_16.pt\"\n",
    "\n",
    "    for key in gap_models_dict:\n",
    "        gap_models_dict[key] = torch.load(gap_models_dict[key], map_location=lambda storage, _: storage)\n",
    "else:\n",
    "    state_dict = torch.load(\n",
    "        f\"{save_path}/model/{params['model']}_state_dict_best.pt\",\n",
    "        map_location=lambda storage, _: storage,\n",
    "    )\n",
    "\n",
    "    model = load_model(params[\"model\"], params).to(device)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = params[\"model\"]\n",
    "dataset = params[\"dataset\"]\n",
    "\n",
    "if model_name == \"ours\":\n",
    "    physics_loss = params[\"physics_loss\"]\n",
    "    train_hybrid = params[\"train_hybrid\"]\n",
    "\n",
    "statistic_metrics = True\n",
    "\n",
    "print(f\"-Model name : {model_name}\")\n",
    "print(f\"-Dataset : {dataset}\")\n",
    "print(f\"-Compute statistic_metrics : {statistic_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keys = [\"pred\"]\n",
    "ret_keys = [\"n_frames\", \"n_missings\"]\n",
    "if model.params[\"model\"] == \"ours\":\n",
    "    if model.params[\"physics_loss\"]:\n",
    "        model_keys += [\"physics_f\", \"physics_b\"]\n",
    "    if model.params[\"train_hybrid\"]:\n",
    "        model_keys += [\"static_hybrid\", \"static_hybrid2\", \"train_hybrid\"]\n",
    "if statistic_metrics:\n",
    "    model_keys += [\"linear\", \"knn\", \"forward\"]\n",
    "\n",
    "    metrics = [\"speed\", \"change_of_step_size\", \"path_length\"]\n",
    "    ret_keys += [f\"{m}_{metric}\" for m in model_keys for metric in metrics]\n",
    "\n",
    "ret_keys += [f\"{m}_dist\" for m in model_keys]\n",
    "total_ret = {key: 0 for key in ret_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrica_files = [\"match1.csv\", \"match2.csv\", \"match3_valid.csv\", \"match3_test.csv\"]\n",
    "metrica_paths = [f\"data/metrica_traces/{f}\" for f in metrica_files]\n",
    "\n",
    "nba_files = os.listdir(\"data/nba_traces\")\n",
    "nba_paths = [f\"data/nba_traces/{f}\" for f in nba_files]\n",
    "nba_paths.sort()\n",
    "\n",
    "nfl_files = os.listdir(\"data/nfl_traces\")\n",
    "nfl_paths = [f\"data/nfl_traces/{f}\" for f in nfl_files if f.endswith(\".csv\")]\n",
    "nfl_paths.sort()\n",
    "\n",
    "if dataset == \"soccer\":\n",
    "    trace_helper = TraceHelper\n",
    "    test_data_paths = metrica_paths[3:4]\n",
    "elif dataset == \"basketball\":\n",
    "    trace_helper = NBADataHelper\n",
    "    test_data_paths = nba_paths[90:]\n",
    "else: # e.g. \"American football\"\n",
    "    trace_helper = NFLDataHelper\n",
    "    test_data_paths = nfl_paths[0:1]\n",
    "\n",
    "print(f\"Test data paths : {test_data_paths}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in test_data_paths:\n",
    "    print()\n",
    "    print(path,\":\")\n",
    "    match_traces = pd.read_csv(path, header=0, encoding=\"utf-8-sig\")\n",
    "    helper = trace_helper(traces=match_traces)\n",
    "\n",
    "    if model_name == \"nrtsi\":\n",
    "        ret, df_dict = helper.predict(model, gap_models=gap_models_dict, statistic_metrics=statistic_metrics, dataset=dataset)\n",
    "    else:\n",
    "        ret, df_dict = helper.predict(model, statistic_metrics=statistic_metrics, dataset=dataset)\n",
    "\n",
    "    for key, value in ret.items():\n",
    "        total_ret[key] += value\n",
    "        \n",
    "    print()\n",
    "\n",
    "print(\"Total Performance:\")\n",
    "print_helper(total_ret, model_keys, trial=trial, save_txt=True)\n",
    "\n",
    "torch.save(helper, f\"{save_path}/helper\")\n",
    "torch.save(df_dict, f\"{save_path}/df_dict\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Get Main model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 3003\n",
    "save_path = f\"saved/{trial:03d}\"\n",
    "if os.path.isfile(save_path + \"/df_dict\"):\n",
    "    helper =  torch.load(save_path + \"/helper\")\n",
    "    df_dict = torch.load(save_path + \"/df_dict\")\n",
    "    with open(f\"{save_path}/params.json\", \"r\") as f:\n",
    "        params = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Add baseline model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_dict = {4000 : \"brits\", 5000 : \"naomi\", 214 : \"nrtsi\"} # Metrica\n",
    "trial_dict = {4003 : \"brits\", 5001 : \"naomi\", 6001 : \"nrtsi\", 9996 : \"graphimputer\"} # NBA\n",
    "for (t, model_name) in trial_dict.items():\n",
    "    save_path = f\"saved/{t:03d}\"\n",
    "    if os.path.isfile(save_path + \"/df_dict\"):\n",
    "        df_dict_ = torch.load(save_path + \"/df_dict\")\n",
    "        df_dict[f\"{model_name}_df\"] = df_dict_[\"pred_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Soccer Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.traces[\"episode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 479\n",
    "i1 = 873\n",
    "\n",
    "animator = TraceAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target_df\"][i0:i1], \"pred\": df_dict[\"train_hybrid_df\"][i0:i1]},\n",
    "    mask = df_dict[\"mask_df\"][i0:i1],\n",
    "    show_episodes=True,\n",
    "    show_events=False,\n",
    "    show_frames=False,\n",
    "    show_polygon=True,\n",
    "    annot_cols=None,\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Basketball Animator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 326\n",
    "i1 = 737\n",
    "animator = NBADataAnimator(\n",
    "    trace_dict={\"main\": df_dict[\"target_df\"][i0:i1], \"pred\": df_dict[\"train_hybrid_df\"][i0:i1]},\n",
    "    show_episodes=True,\n",
    "    show_frames=True,\n",
    "    masks = df_dict[\"mask_df\"][i0:i1],\n",
    ")\n",
    "anim = animator.run()\n",
    "\n",
    "path = f\"animations/trial_{trial}.mp4\"\n",
    "\n",
    "writer = animation.FFMpegWriter(fps=10)\n",
    "anim.save(path, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = \"imputed_traj\" # \"imputed_traj\", \"dist_heatmap\", \"weights_heatmap\"\n",
    "dataset = params[\"dataset\"]\n",
    "visualizer = VisualizeHelper(trial, df_dict, plot_mode, dataset=dataset, helper=helper)\n",
    "visualizer.valid_episodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.plot_run(epi_idx=0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c44ecce01b6920a996c2e45a7791c773f725b79a727cce05b077a0ad48ece758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
